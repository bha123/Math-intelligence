{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Read the dataset\n\ndata_csv = pd.read_csv('../input/Real estate.csv', error_bad_lines=False)\ndata_csv.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the dataset\nimport matplotlib.pyplot as plt\nx = data_csv['X2 house age']\ny = data_csv['Y house price of unit area']\n\n\n#Converting them into numpy array\nX = np.array(x)\nY = np.array(y)\n\nplt.scatter(X,Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Line equation : \ny = m * x + c \n\ny = output\nm = slope  = (y2 - y1)/(x2 - x1)\nc = y-intercept\n\n\nNow our goal is to create a hypothesis function that can actually predict the value Y based on given X\n\nError = Y (output) - Y(predicted)\n\nMeans Squared error = 1/2 * (Y(output) - Y(predicted))^2\n\n1/2 is taken to reduce the computational complexity\n\nDerivates of Error with respect to m and c \n\n\nRecap of calculus - power rule y = x^n then dy/dx = n*x^(n-1)           - 1\n                  -            y = f(g(x))  then dy/dx = f'(g(x))*g'(x) - 2 \n                               x = constant then dy/dx = 0              - 3   \n                               y = x  then dy/dx = 1                    - 4\n                               \n                               \nGradient are used to identify rate of change of output with respect to change in particular variable\ny(predicted) = y = m*x + c , here y(output) is constant\n\nMean square error \n\nError = 1/2 *( y(output) - y(predicted))^2\n      = 1/2 *( y(output) - (m * x + c))^2\n      \n      \nApplying derivaties with respect to m and c on error function\n\nd(Error)/d(m) = 2 * (1/2 * (y(output) - (m * x + c)))     y(output) is constant\n\n              =   -1 * (m * x + c ) * d(m* x +c)/d(m)   rule no : 2\n              =  -1 *(y- (m*x+c))* x\n                                       \n m_gradient   = -x*(m*x + c)\n              \nd(Error)/d(c) = 2 * (1/2 *( y(output) - (m * x + c))\n              = -(y - (m * x + c))  \n \n c_gradient  = -(y- (m*x+c))\n \n \n #sum it up \n m_gradient   = -x*(y -(m*x + c))\n c_gradient  = -(y -(m*x+c))\n \n # updated gradient values \n \n learning_rate = rate at  which the change will be added taken into by multiplying with gradient (eg: 0.01)\n \n m_updated_Value = m_original - (learning_rate * m_gradient)\n c_updated_value = c_original - (learning_rate * c_gradient)\n \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#initialize m and c\nm = 0\nc = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking iterations of 10000\niterations = 10000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting the learning rate\nlearning_rate = 0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def caliculate_error(x, y, m, c):\n    y_predicted = m * x + c \n    error = (1/2)*((y - y_predicted)**2)\n    error = np.mean(error)\n    return  error\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_value(x,m,c,y, learning_rate):\n    m_gradient = -x*(y - (m*x + c))\n    c_gradient = -(y - (m*x+c))\n    m_new  = m - (learning_rate*m_gradient)\n    c_new  = c - (learning_rate*c_gradient)\n\n    return np.mean(m_new), np.mean(c_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_values = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract M and C values \nfor i in range(iterations):\n    loss_values.append(caliculate_error(X,Y,m,c))\n    m_new, c_new = update_value(X,m,c,Y, learning_rate)\n    m = m_new\n    c = c_new\n    \nprint(loss_values[-1])\nprint(m)\nprint(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the loss_values\n\nplt.plot(loss_values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot line with the updated values \n\nY_latest = (X*m + c)\n\nplt.scatter(X,Y_latest)\nplt.scatter(X,Y)\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}